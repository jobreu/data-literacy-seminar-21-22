{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigene Facebook-Daten explorieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit diesem Notebook können Sie einen Teil Ihrer eigenen Facebook-Daten explorieren. Hierfür müssen Sie eine [Kopie Ihrer persönlichen Facebook-Daten herunterladen](https://www.facebook.com/help/1701730696756992). Wir arbeiten in diesem Notebook mit den Daten im `JSON`-Format, in welchem Sie Ihre Daten dementsprechend exportieren müssen, wenn Sie diese mit diesem Notebook explorieren möchten. Nachdem Sie Ihr Archiv gespeichert haben, müssen Sie die `.zip`-Datei zunächst entpacken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hinweis**: Wenn Sie Ihre Facebook-Daten im `HTML`-Format exportieren, können Sie diese auch lokal in Ihrem Browser explorieren. Hierzu müssen Sie, nachdem Sie die Dateien entpackt haben, auf Ihrem Rechner lokal die Datei `index.html` öffnen. Im Netz gibt es zahlreiche Tutorials dazu, wie man seine Facebook-Daten exportiert und die `HTML`-Dateien mithilfe des Browsers explorieren kann (z.B. [dieses hier](https://www.makeuseof.com/tag/download-entire-facebook-history-data-downloader/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor wir mit den Daten in den exportierten `JSON`-Files arbeiten können, müssen diese zunächst \"repariert\" werden. Grund hierfür ist ein Fehler in der [Zeichenkodierung](https://de.wikipedia.org/wiki/Zeichenkodierung), die dazu führt, dass die Textdaten nicht richtig dargestellt werden (es handelt sich hierbei um ein sogenanntes [Mojibake](https://en.wikipedia.org/wiki/Mojibake)). Um dies zu beheben, können wir den [`Python`](https://www.python.org/)-Code im Notebok [fix_fb_data_encoding](./fix_fb_data_encoding.ipynb) nutzen. Hierfür müssen Sie die entsprechenden Dateien hier hochladen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook explorieren wir Daten zu Posts, Freunden sowie Reaktionen auf Facebook (um Nachrichten aus dem Facebok Messenger zu explorieren, können Sie z.B. das Tool [FB Message Explorer](https://github.com/adurivault/FBMessage) nutzen). Hierzu benötigen folgende Dateien: `your_posts_1.json` (Facebook-Posts), `posts_and_comments.json` (Kommentare und Reaktionen) und `friends.json` (Daten zu Facebook-Freunden). Die Dateien sollten hier im Ordner *data* gespeichert werden. Öffnen Sie diesen (durch Doppelklick auf den Ordnernamen) im File Explorer auf der linken Seite und nutzen dann den *Upload Files*-Button im Menü oben links (das Symbol ist ein Pfeil über einem Strich). Wählen Sie darüber die entsprechenden `JSON`-Dateien von Ihrem lokalen Rechner aus und laden Sie diese in den Ordner *data* hoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hinweis**: Wenn Sie Facebook schon sehr lange und/oder sehr intensiv nutzen können die Dateien recht groß sein. In diesem Fall können der Upload sowie das Einlesen (im Code weiter unten) etwas länger dauern (dies gilt ggf. auch für das lokale Öffnen und Bearbeiten der Datei)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB**: Bevor Sie mit diesem Notebook arbeiten können, müssen Sie nach dem Upload der benötigten Dateien den Code im Notebok [fix_fb_data_encoding](./fix_fb_data_encoding.ipynb) ausführen. Wenn Sie dies gemacht haben, können Sie mit diesem Notebook fortfahren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zur Erinnerung**: Ihre persönliche Kopie des Notebooks sowie alle Dateien, die Sie hochladen, werden am Ende der Nutzungssitzung gelöscht. Wenn Sie aber ganz \"auf Nummer sicher gehen\" wollen, können Sie die Dateien mit Ihren Facebook-Daten über den File Explorer auf der linken Seite nach dem Durcharbeiten dieses Notebooks auch manuell löschen: Rechtsklick auf den Dateinamen und dann *Delete* auswählen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pakete laden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie auch in den anderen Notebooks müssen wir zunächst die benötigten `R`-Pakete laden. Im Vergleich zum [Notebook für die Twitterdaten](./tweets.ipynb) laden wir hier zwei weitere Pakete. Eins zur Aufbereitung der Daten ([`tidyr`](https://tidyr.tidyverse.org/)) und eins zur automatischen Erkennung von Sprache in Texten ([`cld3`](https://github.com/ropensci/cld3)). Bevor wir die Pakete laden können, müssen wir noch das Paket `stopwords` (nach-)installieren, um später im Notebook auch mit deutschsprachigen Tweets arbeiten zu können (NB: die Installation dieses Pakets kann ein paar Minuten dauern)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(jsonlite)\n",
    "library(magrittr)\n",
    "library(tidyr)\n",
    "library(dplyr)\n",
    "library(lubridate)\n",
    "library(ggplot2)\n",
    "library(scales)\n",
    "library(stringr)\n",
    "library(cld3)\n",
    "library(tidytext)\n",
    "library(stopwords)\n",
    "library(wordcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freunde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst schauen wir uns die Daten zu Freundschaften auf Facebook an. Hierzu müssen wir die entsprechende `JSON`-Datei einlesen und diese in ein `data.frame`-Objekt umwandeln, mit dem wir in `R` arbeiten können"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_friends <- fromJSON(\"./data/fb_friends.json\")\n",
    "fb_friends_df <- as.data.frame(fb_friends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um einen ersten Eindruck von diesen Daten zu bekommen, können wir uns die Variablennamen sowie die ersten zehn Fälle bzw. Zeilen anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(fb_friends_df)\n",
    "head(fb_friends_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wollen nun visualisieren, wie viele neue Facebook-Freunde wir pro Monat gewonnen haben. Hierzu müssen wir das Format der Zeitstempel anpassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_friends_df <- fb_friends_df %>% \n",
    "  mutate(timedate = as_datetime(friends.timestamp),\n",
    "         timedate = with_tz(timedate, tzone = \"Europe/Berlin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir uns anschauen, wie viele neue Facebook-Freunde wir im Laufe unserer Nutzung gewonnen haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_friends_df %>%\n",
    "  mutate(time_floor = floor_date(timedate, unit = \"1 month\")) %>%\n",
    "  count(time_floor) %>%\n",
    "  ggplot(aes(x = as.Date(time_floor), y = n)) +\n",
    "  geom_bar(stat = \"identity\") +\n",
    "  scale_x_date(breaks = function(x) seq.Date(from = min(x), to = max(x), by = \"6 months\"),\n",
    "               minor_breaks = function(x) seq.Date(from = min(x), to = max(x), by = \"1 month\"),\n",
    "               labels = date_format(\"%m-%Y\"),\n",
    "               expand = expansion(mult=c(0,0))) +\n",
    "  scale_y_continuous(expand = expansion(mult=c(0,0.05))) +\n",
    "  labs(title = \"Anzahl neuer Facebook-Freunde pro Monat\",\n",
    "       x = \"Monat\",\n",
    "       y = \"Neue Facebook-Freunde\") +\n",
    "  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vielleicht interessiert uns auch, wann wie unseren ersten Facebook-Freund bzw. unsere erste Facebook-Freundin hinzugefügt haben und wann wir dies zuletzt gemacht haben (vor Export der Daten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(fb_friends_df$timedate)\n",
    "max(fb_friends_df$timedate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reaktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt befassen wir uns mit Reaktionen auf Posts, Kommentare etc. Auch hierfür müssen wir im ersten Schritt die Daten einlesen und diese in ein Format bringen, mit dem wir arbeiten können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_reactions <- fromJSON(\"./data/fb_reactions.json\")\n",
    "fb_reactions_df <- as.data.frame(fb_reactions)\n",
    "fb_reactions_df <- unnest(fb_reactions_df, reactions.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Format, in dem die Daten vorliegen, ist in diesem Fall etwas komplizierter (man könnte auch sagen verschachtelter), weswegen zusätzliche Aufbereitungsschritte nötig sind,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_df <- bind_rows(fb_reactions_df$reaction)\n",
    "\n",
    "fb_reactions_df <- fb_reactions_df %>% \n",
    "  select(reactions.timestamp, reactions.title) %>% \n",
    "  mutate(timedate = as_datetime(reactions.timestamp),\n",
    "         timedate = with_tz(timedate, tzone = \"Europe/Berlin\")) %>% \n",
    "  bind_cols(reactions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch für diese Daten können wir uns anschauen, wie sie nun strukturiert sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(fb_reactions_df)\n",
    "head(fb_reactions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was sind meine häufigsten Reaktionen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_reactions_df %>% \n",
    "  count(reaction) %>% \n",
    "  arrange(-n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf welche Inhalte reagiere ich am häufigsten? Um diese Frage zu beantworten müssen wir aus der Variable `reactions.title` die Information extrahieren, auf was reagiert wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_reactions_df <- fb_reactions_df %>% \n",
    "  mutate(react_content = factor(case_when(\n",
    "    str_detect(reactions.title, \"Beitrag\") ~ \"post\",\n",
    "    str_detect(reactions.title, \"Foto\") ~ \"photo\",\n",
    "    str_detect(reactions.title, \"Kommentar\") ~ \"comment\",\n",
    "    str_detect(reactions.title, \"Video\") ~ \"video\",\n",
    "    str_detect(reactions.title, \"GIF\") ~ \"GIF\",\n",
    "    str_detect(reactions.title, \"Link\") ~ \"link\",\n",
    "    str_detect(reactions.title, \"Album\") ~ \"photo album\",\n",
    "    str_detect(reactions.title, \"Lebensereignis\") ~ \"life event\",\n",
    "    str_detect(reactions.title, \"Aktivität\") ~ \"activity\",\n",
    "    str_detect(reactions.title, \"Notiz\") ~ \"note\",\n",
    "    str_detect(reactions.title, \"dass\") ~ \"like\"\n",
    "  )))\n",
    "\n",
    "fb_reactions_df %>% \n",
    "  count(react_content) %>% \n",
    "  arrange(-n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abschließend explorieren wir die Inhalte unserer Posts auf Facebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie immer müssen die Daten zunächst einmal eingelesen und aufbereitet werden,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_posts_json <- fromJSON(\"./data/fb_posts.json\")\n",
    "\n",
    "fb_posts_df <- fb_posts_json %>% \n",
    "  unnest(data) %>% \n",
    "  select(timestamp, title, post, tags) %>% \n",
    "  mutate(timedate = as_datetime(timestamp),\n",
    "         timedate = with_tz(timedate, tzone = \"Europe/Berlin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie sehen die Daten aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(fb_posts_df)\n",
    "head(fb_posts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Über die Variable `title` lässt sich erkennen, um welche Art von Post es sich handelt (z.B. Post in der Chronik einer anderen Person, Status-Update, teilen von Inhalten etc.). Diese könnte man auch verwenden, um die Exploration der Daten auf bestimmte Arten von Posts zu beschränken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Von wann sind der älteste und aktuellste Post in den Daten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(fb_posts_df$timedate)\n",
    "max(fb_posts_df$timedate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um herauszufinden, wen ich in meinen Posts am häufigsten markiere, ist weitere Datenaufbereitungsarbeit nötig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_posts_df <- fb_posts_df %>% \n",
    "  mutate(mentions = sapply(tags, toString))\n",
    "\n",
    "fb_posts_df <- fb_posts_df %>% \n",
    "  mutate(nr_mentions = ifelse(mentions == \"\", 0, (str_count(mentions, \",\")) + 1))\n",
    "\n",
    "max(fb_posts_df$nr_mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im letzten Schritt in der obigen Code-Zelle wird die maximale Anzahl von Markierungen in einem Post festgestellt. Diese fällt tendenziell bei jedem anders aus. Daher müssen Sie den Code in der nachfolgenden Zelle ggf. entsprechend anpassen, um die für ihre Daten korrekte Anzahl von Variablen für die einzelnen Mentions festzulegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags <- fb_posts_df %>% \n",
    "  separate(mentions, c(\"tag1\", \"tag2\", \"tag3\", \"tag4\", \"tag5\", \"tag6\", \"tag7\", \"tag8\"), \", \") %>% \n",
    "  select(tag1:tag8) %>% \n",
    "  filter(tag1 != \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir zählen, wenn wir in unseren Posts am häufigsten markieren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags %>% \n",
    "  pivot_longer(everything(), names_to = \"tag_nr\", values_to = \"name\") %>% \n",
    "  filter(!is.na(name)) %>% \n",
    "  count(name) %>% \n",
    "  arrange(-n) %>% \n",
    "  head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worthäufigkeiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das meiste, was in diesem Abschnitt gemacht wird, ist analog zum dem, was im Notebook [tweets.ipynb](./tweets.ipynb) für Tweets geschieht. Da die Daten unterschiedlich strukturiert sind, unterscheidet sich der Code an einigen Stellen allerdings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für unsere Analyse möchten wir Links (URLs) und Mentions ausschließen. Daher legen wir mithilfe von [Regular Expressions](https://de.wikipedia.org/wiki/Regul%C3%A4rer_Ausdruck) Muster fest, um diese entsprechen aus den Texten der Posts zu entfernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pattern <- \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "tag_pattern <- \"@\\\\[.*\\\\]\"\n",
    "\n",
    "fb_posts_df <- fb_posts_df %>% \n",
    "  mutate(post_clean = str_replace(post, url_pattern, \"\"),\n",
    "         post_clean = str_replace(post_clean, tag_pattern, \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anders als bei den Daten zu den Tweets ist in denjenigen zu den Facebook-Posts die Information dazu, in welcher Sprache diese verfasst wurden (bzw. welche Sprache das genutzte automatisierte Verfahren erkannt hat) nicht enthalten. Daher müssen wir für die Erkennung der Sprache ein zusätzliches Paket nutzen. Wir verwenden das Paket [`cld3`](https://github.com/ropensci/cld3), welches eine Implementation des *Compact Language Detector 3* von Google für `R` ist. Ähnlich wie bei der Language Detection von Twitter funktioniert das natürlich nicht 100%ig. Es gibt auch weitere `R`-Pakete, die man zur Erkennung der Sprache von Texten nutzen kann, wie z.B. das Paket [`tecxtcat`](https://cran.r-project.org/web/packages/textcat/index.html). Man kann diese Pakete auch in Kombination verwenden. Welche Lösungen man nutzt bzw. kombiniert hängt auch davon ab, wie wichtig für die jeweilige Aufgabe [False Positives und False Negatives](https://en.wikipedia.org/wiki/False_positives_and_false_negatives) bei der Erkennung sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_posts_df <- fb_posts_df %>% \n",
    "  mutate(lang_g = detect_language(fb_posts_df$post_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welche Sprachen wurden erkannt und wie häufig jeweils?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_posts_df %>% \n",
    "  count(lang_g) %>% \n",
    "  arrange(-n) %>% \n",
    "  head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die nächsten Schritte sind dieselben, wie für die Auszählung und Visualisierung der Worthäufigkeiten in Tweets, wie sie im Notebook [tweets.ipynb](./tweets.ipynb) umgesetzt sind: Die Tweets werden in einzelne Wörter aufgeteilt ([Tokenization](https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization)) und dann werden [Stoppwörter](https://de.wikipedia.org/wiki/Stoppwort) entfernt. An den Beispielen wird deutlich, dass es auf die Ergebnisse einen großen Einfluss hat, welche der sogenannten Preprocessing-Methoden (z.B. Language Detection, Tokenization und Stopword Removal) man einsetzt, in welcher Reihenfolge man dies macht und welche Tools man dazu verwendet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst schauen wir uns die gesamten Posts an (d.h. nicht nach erkannter Sprache gefiltert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_posts <- fb_posts_df %>% \n",
    "  unnest_tokens(word, post_clean)\n",
    "\n",
    "stop_words_de <- get_stopwords(language = \"de\")\n",
    "\n",
    "fb_posts_clean <- fb_posts %>% \n",
    "  filter(!word %in% stop_words$word,\n",
    "         !word %in% stop_words_de$word,\n",
    "         str_detect(word, \"[a-z]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_posts_clean %>% \n",
    "  count(word, sort = T) %>% \n",
    "  top_n(10) %>% \n",
    "  mutate(word = reorder(word, n)) %>% \n",
    "  ggplot(aes(x = word, y = n)) +\n",
    "  geom_col() +\n",
    "  labs(x = NULL, y = \"Häufigkeit\") +\n",
    "  coord_flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun vergleichen wir die deutsch- und englischsprachigen Facebook-Posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_de <- fb_posts %>% \n",
    "  filter(lang_g == \"de\",\n",
    "         !word %in% stop_words_de$word,\n",
    "         str_detect(word, \"[a-z]\"))\n",
    "\n",
    "posts_de %>% \n",
    "  count(word, sort = T) %>% \n",
    "  top_n(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Liste der häufigsten deutschen Wörter in den Posts sehen wir einige Wörter, die man tendenziell auch als Stoppwörter bezeichnen kann. Diese sind offenbar nicht in der Liste der deutschen Stoppwörter aus dem Paket `stopwords` enthalten. Um diese aus unseren Analysen auszuschließen, können wir zusätlich eine Liste mit eigenen Stoppwörtern definieren (im nachfolgenden Code `custom_stops` genannt). Für Ihre eigenen Daten müssen Sie diese Liste natürlich entsprechend anpassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stops <- c(\"dass\", \"gibt\", \"mal\", \"ja\")\n",
    "\n",
    "posts_de %>% \n",
    "  filter(!word %in% custom_stops) %>% \n",
    "  count(word, sort = T) %>% \n",
    "  top_n(10) %>% \n",
    "  mutate(word = reorder(word, n)) %>% \n",
    "  ggplot(aes(x = word, y = n)) +\n",
    "  geom_col() +\n",
    "  labs(x = NULL, y = \"Häufigkeit\") +\n",
    "  coord_flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Vergleich die Wörter aus den Posts, die als englischsprachig identifiziert wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_en <- fb_posts %>% \n",
    "  filter(lang_g == \"en\",\n",
    "         !word %in% stop_words$word,\n",
    "         str_detect(word, \"[a-z]\"))\n",
    "\n",
    "posts_en %>% \n",
    "  count(word, sort = T) %>% \n",
    "  top_n(10) %>% \n",
    "  mutate(word = reorder(word, n)) %>% \n",
    "  ggplot(aes(x = word, y = n)) +\n",
    "  geom_col() +\n",
    "  labs(x = NULL, y = \"Häufigkeit\") +\n",
    "  coord_flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und der direkte visuelle Vergleich der Worthäufigkeiten zwischen deutschen und englischen Posts (hierfür müssen wir die Daten wieder kombinieren)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_combined <- posts_en %>% \n",
    "  bind_rows(posts_de)\n",
    "\n",
    "posts_combined %>% \n",
    "  filter(!word %in% custom_stops) %>% \n",
    "  count(word, lang_g, sort = T) %>% \n",
    "  ungroup %>% \n",
    "  group_by(lang_g) %>%\n",
    "  top_n(10, n) %>%\n",
    "  ungroup() %>%\n",
    "  mutate(word = reorder(word, n, fill = lang_g)) %>% \n",
    "  ggplot(aes(x = word, y = n)) +\n",
    "  geom_col(show.legend = FALSE) +\n",
    "  facet_wrap(~lang_g, scales = \"free_y\") +\n",
    "  labs(x = NULL, y = \"Häufigkeit\") +\n",
    "  coord_flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und zum Abschluss nochmal eine bunte Wortwolke mit Wörtern aus allen Posts. Ggf. macht es hier für Ihre eigenen Daten Sinn, die Mindeshäufigkeit (`min.freq`) sowie die maximale Anzahl (`max.words`) der dargestellten Wörter anzupassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqs <- fb_posts_clean %>% \n",
    "  count(word) %>% \n",
    "  rename(freq = n)\n",
    "\n",
    "wordcloud(words = word_freqs$word,\n",
    "          freq = word_freqs$freq,\n",
    "          min.freq = 20,\n",
    "          max.words = 50,\n",
    "          random.order = FALSE,\n",
    "          rot.per = 0.35,\n",
    "          colors = brewer.pal(8, \"Dark2\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
